{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-17T09:25:30.450535Z","iopub.execute_input":"2023-02-17T09:25:30.451027Z","iopub.status.idle":"2023-02-17T09:25:30.479738Z","shell.execute_reply.started":"2023-02-17T09:25:30.450911Z","shell.execute_reply":"2023-02-17T09:25:30.479116Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.481016Z","iopub.execute_input":"2023-02-17T09:25:30.481220Z","iopub.status.idle":"2023-02-17T09:25:30.486176Z","shell.execute_reply.started":"2023-02-17T09:25:30.481194Z","shell.execute_reply":"2023-02-17T09:25:30.485020Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(r'/kaggle/input/tesla-stock-price/Tesla.csv - Tesla.csv.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.487572Z","iopub.execute_input":"2023-02-17T09:25:30.487808Z","iopub.status.idle":"2023-02-17T09:25:30.567843Z","shell.execute_reply.started":"2023-02-17T09:25:30.487779Z","shell.execute_reply":"2023-02-17T09:25:30.566524Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_20/992822060.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/kaggle/input/tesla-stock-price/Tesla.csv - Tesla.csv.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/tesla-stock-price/Tesla.csv - Tesla.csv.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/tesla-stock-price/Tesla.csv - Tesla.csv.csv'","output_type":"error"}]},{"cell_type":"code","source":"df=data.reset_index()['Close']\nplt.plot(data['Date'],df)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.568661Z","iopub.status.idle":"2023-02-17T09:25:30.569303Z","shell.execute_reply.started":"2023-02-17T09:25:30.569115Z","shell.execute_reply":"2023-02-17T09:25:30.569132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 資料 scaling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler(feature_range=(0,1))\ndf1=scaler.fit_transform(np.array(df).reshape(-1,1))\ndf1","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.570031Z","iopub.status.idle":"2023-02-17T09:25:30.570720Z","shell.execute_reply.started":"2023-02-17T09:25:30.570570Z","shell.execute_reply":"2023-02-17T09:25:30.570587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 法Ａ\n##splitting dataset into train and test split\n'''\ntraining_size=int(len(df1)*0.7)\ntest_size=len(df1)-training_size\ntrain_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]\n'''\n### 法Ｂ\n### 這個方法錯誤！ 為什麼？ 提示：random_state\n'''\nfrom sklearn.model_selection import train_test_split\nX = df1\ny = df1\ntrain_data, test_data, _, _ = train_test_split(X,y,test_size=0.3,random_state=0)\n'''\n### 法Ｃ\n### 不要 shuffle\n## https://stackoverflow.com/questions/43838052/how-to-get-a-non-shuffled-train-test-split-in-sklearn\nfrom sklearn.model_selection import train_test_split\nX = df1\ny = df1\ntrain_data, test_data, _, _ = train_test_split(X,y,test_size=0.3, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.571361Z","iopub.status.idle":"2023-02-17T09:25:30.571965Z","shell.execute_reply.started":"2023-02-17T09:25:30.571776Z","shell.execute_reply":"2023-02-17T09:25:30.571801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 用這格比較 法ＡＢＣ的結果差異\nplt.plot(df1)\nplt.plot(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.572672Z","iopub.status.idle":"2023-02-17T09:25:30.572960Z","shell.execute_reply.started":"2023-02-17T09:25:30.572802Z","shell.execute_reply":"2023-02-17T09:25:30.572816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.573644Z","iopub.status.idle":"2023-02-17T09:25:30.573899Z","shell.execute_reply.started":"2023-02-17T09:25:30.573759Z","shell.execute_reply":"2023-02-17T09:25:30.573775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, time_step=1):\n    dataX = []\n    dataY = []\n    for i in range(len(dataset)-time_step):#N,n,t.....n=t+2\n        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----9\n        dataX.append(a)\n        dataY.append(dataset[i + time_step, 0])\n    return np.array(dataX), np.array(dataY)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.575847Z","iopub.status.idle":"2023-02-17T09:25:30.576239Z","shell.execute_reply.started":"2023-02-17T09:25:30.576069Z","shell.execute_reply":"2023-02-17T09:25:30.576088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshape into X=t,t+1,t+2,t+3 and Y=t+4\ntime_step = 10\nX_train, y_train = create_dataset(train_data, time_step)\nX_test, y_test = create_dataset(test_data, time_step)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.642808Z","iopub.execute_input":"2023-02-17T09:25:30.643128Z","iopub.status.idle":"2023-02-17T09:25:30.658027Z","shell.execute_reply.started":"2023-02-17T09:25:30.643096Z","shell.execute_reply":"2023-02-17T09:25:30.656776Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_20/4280708375.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reshape into X=t,t+1,t+2,t+3 and Y=t+4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtime_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_dataset' is not defined"],"ename":"NameError","evalue":"name 'create_dataset' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# reshape input to be [samples, time steps, features] which is required for LSTM\n\nX_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n\nprint(X_train.shape), print(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.658835Z","iopub.status.idle":"2023-02-17T09:25:30.659149Z","shell.execute_reply.started":"2023-02-17T09:25:30.658997Z","shell.execute_reply":"2023-02-17T09:25:30.659013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Create the Stacked LSTM model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.663681Z","iopub.status.idle":"2023-02-17T09:25:30.664688Z","shell.execute_reply.started":"2023-02-17T09:25:30.664450Z","shell.execute_reply":"2023-02-17T09:25:30.664476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LSTM魔法陣\nmodel=Sequential()\nmodel.add(LSTM(50,return_sequences=True,input_shape=(time_step,1)))#input10,output50\nmodel.add(LSTM(50,return_sequences=True))#output50，input來自前面\nmodel.add(LSTM(50))#output50，input來自前面\n\n\nmodel.add(Dense(1))#收斂為1\nmodel.compile(loss='mean_squared_error',optimizer='adam')#","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.665717Z","iopub.status.idle":"2023-02-17T09:25:30.666042Z","shell.execute_reply.started":"2023-02-17T09:25:30.665867Z","shell.execute_reply":"2023-02-17T09:25:30.665880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\n#none值就是不要specify它\n#取決於電腦cpu","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.666978Z","iopub.status.idle":"2023-02-17T09:25:30.667252Z","shell.execute_reply.started":"2023-02-17T09:25:30.667107Z","shell.execute_reply":"2023-02-17T09:25:30.667121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=64,verbose=1)\n#none = batch_size=64\n#epocha = 回合","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.668362Z","iopub.status.idle":"2023-02-17T09:25:30.668606Z","shell.execute_reply.started":"2023-02-17T09:25:30.668476Z","shell.execute_reply":"2023-02-17T09:25:30.668489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-02-17T09:25:30.670035Z","iopub.status.idle":"2023-02-17T09:25:30.670294Z","shell.execute_reply.started":"2023-02-17T09:25:30.670158Z","shell.execute_reply":"2023-02-17T09:25:30.670171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Lets Do the prediction and check performance metrics\ntrain_predict=model.predict(X_train)\ntest_predict=model.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Transformback to original form\ntrain_predict=scaler.inverse_transform(train_predict)\ntest_predict=scaler.inverse_transform(test_predict)\n#因為標準化過\ntrain_predict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nfrom sklearn.metrics import mean_squared_error\nmath.sqrt(mean_squared_error(y_train,train_predict))\n#算performancem,越小越好","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Test Data RMSE\nmath.sqrt(mean_squared_error(y_test,test_predict))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(scaler.inverse_transform(df1),'blue')\nplt.plot(train_predict,'red')\nplt.plot(test_predict,'green')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Plotting \n# shift train predictions for plotting\ntime_step=10\ntrainPredictPlot = np.empty_like(df1)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[time_step:len(train_predict)+time_step, :] = train_predict#平移\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(df1)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_predict)+(time_step*2):len(df1), :] = test_predict\n\n\n# plot baseline and predictions\n\nplt.plot(scaler.inverse_transform(df1),'blue')\nplt.plot(trainPredictPlot,'red')\nplt.plot(testPredictPlot,'green')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}